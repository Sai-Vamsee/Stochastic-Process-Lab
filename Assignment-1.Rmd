22229-Assignment-1

Q:Simulate the first 20 letters (vowel/consonant) of the Pushkin poem Markovchain of Example 2.2.

```{r}
# Transition matrix
transition_matrix <- matrix(c(0.175, 0.825, 0.526, 0.474), nrow = 2, byrow = TRUE, dimnames = list(c("v", "c"), c("v", "c")))

# Function to sample the next letter type based on transition probabilities
sample_next_letter <- function(current_letter) {
  letter_type <- ifelse(current_letter == "v", "c", "v")
  sample(c("v", "c"), size = 1, prob = transition_matrix[letter_type, ])
}

# Initial letter type
current_letter <- "v"  # Start with vowel as per the example

# Simulate the first 20 letters
simulated_letters <- c(current_letter)
for (i in 2:20) {
  next_letter <- sample_next_letter(current_letter)
  simulated_letters <- c(simulated_letters, next_letter)
  current_letter <- next_letter
}

# Print the simulated sequence
cat("Simulated letter sequence:", paste(simulated_letters, collapse = " "))

```

Q:The behavior of dolphins in the presence of tour boats in Patagonia,Argentina is studied in Dans et al. (2012). A Markov chain model is developed, with state space consisting of five primary dolphin activities (socializing,traveling, milling, feeding, and resting).The following transition matrix is obtained.
Use technology to estimate the long-term distribution of dolphin activity

```{r}
data<-c(0.84,0.11,0.01,0.04,0, 0.03,0.8,0.04,0.1,0.03, 0.01,0.15,0.7,0.07,0.07, 0.03,0.19,0.02,0.75,0.01, 0.03,0.09,0.05,0,0.83)
mat<-matrix(data,nrow=5,ncol=5,byrow=TRUE)
print(mat)

# to find the long term distibution
long_term<-function(mat){
  result_ei<-eigen(t(mat))
  eigval<-result_ei$values
  eigvec<-result_ei$vectors
  index<-which(abs(eigval-1)<1e-8)
  long_term_dist<-eigvec[,index]/sum(eigvec[,index])
  return(long_term_dist)
}

long_term_dist<-long_term(mat)
print(long_term_dist)


```

Q: In computer security applications, a honeypot is a trap set on a network to detect and counteract computer hackers. Honeypot data are studied in Kimouet al. (2010) using Markov chains. The authors obtain honeypot data from a central database and observe attacks against four computer ports—80, 135,139, and 445—over 1 year. The ports are the states of a Markov chain along with a state corresponding to no port is attacked. Weekly data are monitored,and the port most often attacked during the week is recorded. The estimated Markov transition matrix for weekly attacks is.

with initial distribution � = (0, 0, 0, 0, 1).
(a) Which are the least and most likely attacked ports after 2 weeks?
(b) Find the long-term distribution of attacked ports.

```{r}
# Transition matrix
transition_matrix3 <- matrix(c(
  0, 0, 0, 1, 0,
  0.8/13, 3/13, 1/13, 1/13, 8/13,
  1/16, 3/16, 3/8, 1/4, 1/8,
  0, 1/11, 4/11, 5/11, 1/11,
  0, 1/8, 1/2, 1/8, 1/4
), nrow = 5, byrow = TRUE)

# Initial distribution
initial_distribution <- c(0, 0, 0, 0, 1)

# (a) Calculate the distribution after 2 weeks
distribution_after_2_weeks <- initial_distribution %*% (transition_matrix3 ^ 2)

# Print the distribution after 2 weeks
cat("Distribution of attacked ports after 2 weeks:\n")
cat("Port 80:", distribution_after_2_weeks[1], "\n")
cat("Port 135:", distribution_after_2_weeks[2], "\n")
cat("Port 139:", distribution_after_2_weeks[3], "\n")
cat("Port 445:", distribution_after_2_weeks[4], "\n")
cat("No Attack:", distribution_after_2_weeks[5], "\n")

# (b) Find the long-term distribution using matrix multiplication
steady_state <- matrix(1, nrow = 1, ncol = 5)
for (i in 1:1000) {
  steady_state <- steady_state %*% transition_matrix3
}

# Normalize the long-term distribution
steady_state <- steady_state / sum(steady_state)

# Print the long-term distribution
cat("\nLong-term distribution of attacked ports:\n")
cat("Port 80:", steady_state[1], "\n")
cat("Port 135:", steady_state[2], "\n")
cat("Port 139:", steady_state[3], "\n")
cat("Port 445:", steady_state[4], "\n")
cat("No Attack:", steady_state[5], "\n")

```

Q:See gamblersruin.R. Simulate gambler’s ruin for a gambler with initial stake $2, playing a fair game.
(a) Estimate the probability that the gambler is ruined before he wins $5.
(b) Construct the transition matrix for the associated Markov chain. Estimate
the desired probability in (a) by taking high matrix powers.
(c) Compare your results with the exact probability

```{r}
# Function to simulate gambler's ruin problem
simulate_gamblers_ruin <- function(initial_stake, target_stake, probability, num_simulations) {
  ruins_count <- 0
  
  for (i in 1:num_simulations) {
    current_stake <- initial_stake
    
    while (current_stake > 0 && current_stake < target_stake) {
      if (runif(1) < probability) {
        current_stake <- current_stake + 1  # Win $1
      } else {
        current_stake <- current_stake - 1  # Lose $1
      }
    }
    
    if (current_stake == 0) {
      ruins_count <- ruins_count + 1
    }
  }
  
  return(ruins_count / num_simulations)
}

# Parameters
initial_stake <- 2
target_stake <- 5
probability <- 0.5  # Fair game
num_simulations <- 100000

# (a) Estimate the probability of ruin before winning $5
estimated_probability <- simulate_gamblers_ruin(initial_stake, target_stake, probability, num_simulations)
cat("Estimated probability of ruin before winning $5:", estimated_probability, "\n")

# (b) Construct the transition matrix and estimate using matrix powers
transition_matrix <- matrix(c(
  0, 1, 0,
  0.5, 0, 0.5,
  0, 1, 0
), nrow = 3, byrow = TRUE)

# Estimate the desired probability using high matrix powers
num_steps <- 1000
probability_estimate_matrix_powers <- (transition_matrix ^ num_steps)[1, 3]
cat("Estimated probability using matrix powers:", probability_estimate_matrix_powers, "\n")

# (c) Compare with exact probability
exact_probability <- (1 - (probability ^ initial_stake)) / (1 - (probability ^ (target_stake + initial_stake)))
cat("Exact probability:", exact_probability, "\n")

```

Q: Simulate 50 steps of the random walk on the graph in Figure 2.1. Repeat the simulation 10 times. How many of your simulations end at vertex c? Compare with the exact long-term probability the walk visits c

```{r}
mat<-c(0,1,0,0,0,0, 1/4,0,1/4,1/4,1/4,0, 0,1/4,0,1/4,1/4,1/4, 0,1/4,1/4,0,1/4,1/4, 0,1/3,1/3,1/3,0,0, 0,0,1/2,1/2,0,0)
transition_mat4<-matrix(mat,nrow=6,ncol=6,byrow=TRUE)
print(transition_mat4)
#random walk function
randwalk<-function(transition_mat4,num_steps,start_vertex){
  n_states<-nrow(transition_mat4)
  curr_vertex<-start_vertex
  walk<-numeric(num_steps)
  for(step in 1:num_steps){
    walk[step]<-curr_vertex
    curr_vertex<-sample(1:n_states,1,prob=transition_mat4[curr_vertex,])
  }
  return(walk)
}
#num of stimulations
num<-10
# num of steps in each walk
step<-50
# starting vertex
start<-1
num_at_c<-0
for (i in 1:num){
  walk<-randwalk(transition_mat4,step,start)
  if (tail(walk,1)==3){
    num_at_c<-num_at_c+1
  }
}

#calculating the long term probability at vertex c
prob_at_c<-transition_mat4[start,3]
cat("no of stimulations ending at vertex c: ",num_at_c)
cat("\nLong-term probabaility at visiting c: ",prob_at_c)
```

